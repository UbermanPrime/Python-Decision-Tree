{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Random Forest Classifier from Scratch\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this iPython Notebook, we will implement the random forest classification algorithm from scratch, with helps from the C4.5 decision tree classifier that we built previously.  Random forest is an ensemble method of machine learning, wich combines output of various decision tree classifier, and vote for their majority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import c45dtree as dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Samples\n",
    "\n",
    "Random forest would build a set of decision trees.  For each tree, its input data was drawn from the bootstrap samples (random with replacement) of the original data, as shown belows:\n",
    "\n",
    "|Original Data|1|2|3|4|5|6|7|8|9|10|\n",
    "|--|--|--|--|--|--|--|--|--|--|--|\n",
    "|Bagging (1)|7|8|10|8|2|5|10|10|5|9|\n",
    "|Bagging (2)|1|4|9|1|2|3|2|7|3|2|\n",
    "|Bagging (3)|1|8|5|10|5|5|9|6|3|7|\n",
    "\n",
    "For those samples not being drwan at each iteration, they are called out-of-bag samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bagSamples(m):\n",
    "    b = np.random.choice(m, size=m, replace=True)\n",
    "    oob = [i for i in xrange(m) if i not in b]\n",
    "    return b, oob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Features Selection\n",
    "\n",
    "The theory is that the combining of a set of weak classifiers would deliver a strong classifier.  Adding to drawing bootstap sample inputs, We generate a set of weaker decision tree classifiying by only selecting $\\sqrt { n }$ of random features to build trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def buildForest(X, y, forestSize=100, maxDepth=50, minLeafSize=1):\n",
    "    forest = []\n",
    "    oobs = []\n",
    "    \n",
    "    for k in xrange(forestSize):\n",
    "        sys.stdout.write(\"\\rIteration #%d\" % k)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        b, oob = bagSamples(len(y))\n",
    "        X_k = X.iloc[b]\n",
    "        y_k = y.iloc[b]\n",
    "        tree_k = dt.buildTree(X_k, y_k, maxDepth=maxDepth, minLeafSize=minLeafSize, randomFeatrue=True)\n",
    "        forest.append(tree_k)\n",
    "        oobs.append(oob)\n",
    "        \n",
    "    return forest, oobs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vote Classifier Majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictForest(row, forest):\n",
    "    p = []\n",
    "    for k in xrange(len(forest)):\n",
    "        p.append(dt.predictTree(row, forest[k]))\n",
    "\n",
    "    return dt.voteMajority(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-bag Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def oobError(X, y, oobs, forest):\n",
    "    pred = []\n",
    "    hist = []\n",
    "    for k in xrange(len(forest)):\n",
    "        pred.append(X.iloc[oobs[k]].apply(lambda row: dt.predictTree(row, forest[k]), axis=1))\n",
    "        hist.append(pd.DataFrame(pred).apply(lambda col: dt.voteMajority(col)) )\n",
    "        \n",
    "    return pd.DataFrame(hist).apply(lambda row: np.mean((row-y[row.index])**2), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Kaggle Titanic Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #499"
     ]
    }
   ],
   "source": [
    "def submitTitanic():\n",
    "    df = dt.prepareTitanic(\"train.csv\")\n",
    "    X = df[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"Title\", \"HasCabin\", \"FamilySize\"]]\n",
    "    y = df[\"Survived\"]\n",
    "    forest, oobs = buildForest(X, y, forestSize=500, maxDepth=10, minLeafSize=1)\n",
    "\n",
    "    df_test = dt.prepareTitanic(\"test.csv\")\n",
    "    X_test = df_test[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"Title\", \"HasCabin\", \"FamilySize\"]]\n",
    "    p_test = X_test.apply(lambda row: predictForest(row, forest), axis=1)\n",
    "    submission = pd.DataFrame({ \"PassengerId\": df_test[\"PassengerId\"],\n",
    "                                \"Survived\": p_test})\n",
    "    submission.to_csv(\"forest.csv\", index=False)\n",
    "    return forest, oobs\n",
    "\n",
    "#uncomment to run\n",
    "forest, oobs = submitTitanic()\n",
    "#500, 8, 1, 0.80861\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
